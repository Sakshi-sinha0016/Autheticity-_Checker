{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a0bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sakshisinha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import joblib\n",
    "import textstat\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1a22c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n",
      "Buzzwords loaded from config.json: ['\\\\bpassionate about\\\\b', '\\\\bresults-driven\\\\b', '\\\\bteam player\\\\b', '\\\\bhighly motivated\\\\b', '\\\\bdynamic\\\\b', '\\\\bAI enthusiast\\\\b', '\\\\bthought leader\\\\b', '\\\\bproblem solver\\\\b', '\\\\binnovative thinker\\\\b', '\\\\bproven track record\\\\b', '\\\\bstrategic thinker\\\\b', '\\\\bfast learner\\\\b', '\\\\bself-starter\\\\b', '\\\\bgo-getter\\\\b', '\\\\bout-of-the-box thinker\\\\b', '\\\\bvisionary\\\\b', '\\\\bleading-edge\\\\b', '\\\\bdriven by excellence\\\\b', '\\\\bchange agent\\\\b', '\\\\bdisruptive mindset\\\\b', '\\\\bresults-oriented\\\\b', '\\\\bexpert in\\\\b', '\\\\bstrong communication skills\\\\b', '\\\\bexceptional interpersonal skills\\\\b', '\\\\bdedicated professional\\\\b', '\\\\benthusiastic learner\\\\b', '\\\\bworked on multiple projects\\\\b', 'skilled in Python, Java, and C\\\\+\\\\+', '\\\\binterested in AI and ML\\\\b', '\\\\bblockchain believer\\\\b', '\\\\btech-savvy\\\\b', '\\\\blifelong learner\\\\b', '\\\\bdetail-oriented\\\\b']\n"
     ]
    }
   ],
   "source": [
    "with open(\"final_dataset.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "print(\"dataset loaded\")\n",
    "\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "buzzwords = config[\"regex_blacklist\"]\n",
    "print(\"Buzzwords loaded from config.json:\", buzzwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8429fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'profile_data', 'authenticity_score', 'verdict', 'reason', 'flagged_fields']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc1ef44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>profile_data</th>\n",
       "      <th>authenticity_score</th>\n",
       "      <th>verdict</th>\n",
       "      <th>reason</th>\n",
       "      <th>flagged_fields</th>\n",
       "      <th>text</th>\n",
       "      <th>buzzword_count</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aditi Gupta</td>\n",
       "      <td>{'headline': 'E-commerce Content Writer / Copy...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>authentic</td>\n",
       "      <td>Buzzword match and low uniqueness</td>\n",
       "      <td>[headline, bio]</td>\n",
       "      <td>ecommerce content writer copywriter branding s...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aditya Padhi</td>\n",
       "      <td>{'headline': 'Java(DSA), Python (TensorFlow, P...</td>\n",
       "      <td>0.86</td>\n",
       "      <td>authentic</td>\n",
       "      <td>Buzzword match and low uniqueness</td>\n",
       "      <td>[headline, bio]</td>\n",
       "      <td>javadsa python tensorflow pytorch keras numpy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.696709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basava Kusumanjali</td>\n",
       "      <td>{'headline': 'IT Student', 'bio': '3rd year B....</td>\n",
       "      <td>0.26</td>\n",
       "      <td>authentic</td>\n",
       "      <td>Natural language, few red flags</td>\n",
       "      <td>[]</td>\n",
       "      <td>it student 3rd year btech student at sridevi w...</td>\n",
       "      <td>0</td>\n",
       "      <td>24.031029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challa Venkata ramana</td>\n",
       "      <td>{'headline': 'MERN Stack and Machine Learning ...</td>\n",
       "      <td>0.68</td>\n",
       "      <td>authentic</td>\n",
       "      <td>Buzzword match and low uniqueness</td>\n",
       "      <td>[headline, bio]</td>\n",
       "      <td>mern stack and machine learning enthusiast raj...</td>\n",
       "      <td>1</td>\n",
       "      <td>20.825606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debbati Saikrishna</td>\n",
       "      <td>{'headline': 'Fellow at NxtWave's CCBP 4.0 Aca...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>authentic</td>\n",
       "      <td>Natural language, few red flags</td>\n",
       "      <td>[]</td>\n",
       "      <td>fellow at nxtwaves ccbp 40 academy learning fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.848772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id                                       profile_data  \\\n",
       "0            Aditi Gupta  {'headline': 'E-commerce Content Writer / Copy...   \n",
       "1           Aditya Padhi  {'headline': 'Java(DSA), Python (TensorFlow, P...   \n",
       "2     Basava Kusumanjali  {'headline': 'IT Student', 'bio': '3rd year B....   \n",
       "3  Challa Venkata ramana  {'headline': 'MERN Stack and Machine Learning ...   \n",
       "4     Debbati Saikrishna  {'headline': 'Fellow at NxtWave's CCBP 4.0 Aca...   \n",
       "\n",
       "   authenticity_score    verdict                             reason  \\\n",
       "0                0.39  authentic  Buzzword match and low uniqueness   \n",
       "1                0.86  authentic  Buzzword match and low uniqueness   \n",
       "2                0.26  authentic    Natural language, few red flags   \n",
       "3                0.68  authentic  Buzzword match and low uniqueness   \n",
       "4                0.30  authentic    Natural language, few red flags   \n",
       "\n",
       "    flagged_fields                                               text  \\\n",
       "0  [headline, bio]  ecommerce content writer copywriter branding s...   \n",
       "1  [headline, bio]  javadsa python tensorflow pytorch keras numpy ...   \n",
       "2               []  it student 3rd year btech student at sridevi w...   \n",
       "3  [headline, bio]  mern stack and machine learning enthusiast raj...   \n",
       "4               []  fellow at nxtwaves ccbp 40 academy learning fu...   \n",
       "\n",
       "   buzzword_count  readability  \n",
       "0               0    36.030000  \n",
       "1               0    -0.696709  \n",
       "2               0    24.031029  \n",
       "3               1    20.825606  \n",
       "4               1    17.848772  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', re.sub(r'[^A-Za-z0-9\\s]', '', text)).strip().lower()\n",
    "\n",
    "def count_buzzwords_regex(text):\n",
    "    count = 0\n",
    "    for pattern in buzzwords:\n",
    "        try:\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                count += 1\n",
    "        except re.error as e:\n",
    "            print(f\"Invalid regex pattern: {pattern} â€“ {e}\")\n",
    "    return count\n",
    "\n",
    "def compute_readability(text):\n",
    "    try:\n",
    "        return textstat.flesch_reading_ease(text)\n",
    "    except:\n",
    "        return 0.0  # fallback if textstat fails\n",
    "\n",
    "\n",
    "def preprocess(row):\n",
    "    profile = row.get(\"profile_data\", {})\n",
    "    full_text = f\"{profile.get('headline', '')} {profile.get('bio', '')}\"\n",
    "    cleaned = clean_text(full_text)\n",
    "    return pd.Series({\n",
    "        \"text\": cleaned,\n",
    "        \"buzzword_count\": count_buzzwords_regex(cleaned),\n",
    "        \"readability\": compute_readability(full_text)\n",
    "    })\n",
    "\n",
    "\n",
    "processed = df.apply(preprocess, axis=1)\n",
    "df = pd.concat([df, processed], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5862dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X_text = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "import numpy as np\n",
    "X_numeric = df[['buzzword_count', 'readability']].values\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "X = hstack([X_text, csr_matrix(X_numeric)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3f6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['verdict'].map({\n",
    "    'authentic': 1,\n",
    "    'likely_fabricated': 0,\n",
    "    'borderline': 0  \n",
    "})\n",
    "y = df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14b2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba370cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.90      0.67      0.69        11\n",
      "weighted avg       0.85      0.82      0.78        11\n",
      "\n",
      "ROC-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f433d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      1.00      1.00         4\n",
      "   authentic       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df['target'] = df['verdict'].apply(lambda x: 1 if x == 'authentic' else 0)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, df['target'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Optional: detailed classification report\n",
    "print(classification_report(y_test, y_pred, target_names=['fake', 'authentic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cea796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in /model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'model/model.pkl')\n",
    "joblib.dump(vectorizer, 'model/vectorizer.pkl')\n",
    "\n",
    "print (\"model saved in /model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
